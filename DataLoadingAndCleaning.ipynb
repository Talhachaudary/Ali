{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e45a089-f56c-4b4c-8d9a-555a422e107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mysql-connector-python in /home/yousafzai/.local/lib/python3.10/site-packages (9.1.0)\n",
      "Requirement already satisfied: pymongo in /home/yousafzai/.local/lib/python3.10/site-packages (4.10.1)\n",
      "Requirement already satisfied: pandas in /home/yousafzai/.local/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /home/yousafzai/.local/lib/python3.10/site-packages (from pymongo) (2.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/yousafzai/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/yousafzai/.local/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/yousafzai/.local/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "MySQL database created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install necessary libraries (run this if not installed)\n",
    "!pip install mysql-connector-python pymongo pandas\n",
    "\n",
    "# Import mysql.connector and create a MySQL connection without specifying a database\n",
    "import mysql.connector\n",
    "\n",
    "# Connect to MySQL server (without specifying a database)\n",
    "mysql_conn = mysql.connector.connect(\n",
    "    host='localhost',     # Replace with your MySQL host\n",
    "    user='root', # Replace with your MySQL username\n",
    "    password='Root@1234' # Replace with your MySQL password\n",
    ")\n",
    "mysql_cursor = mysql_conn.cursor()\n",
    "\n",
    "# Create the database if it doesn't already exist\n",
    "mysql_cursor.execute(\"CREATE DATABASE IF NOT EXISTS Stock_DB\")\n",
    "print(\"MySQL database created successfully.\")\n",
    "\n",
    "# Now, reconnect to use the new database\n",
    "mysql_conn.database = 'Stock_DB'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b0b61f8-0fbd-48bd-bdcc-7d78ffe195e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoDB database created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import MongoClient and create a MongoDB connection\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to MongoDB server\n",
    "mongo_client = MongoClient('mongodb://localhost:27017/')  # Replace with your MongoDB URI if needed\n",
    "\n",
    "# Define the database\n",
    "mongo_db = mongo_client['Stock_DB']  # Replace with your MongoDB database name\n",
    "print(\"MongoDB database created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8bd5e97-0e50-45fe-a008-c9c6fb92cc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL tables created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Create tables in MySQL\n",
    "# Create table for stock tweets\n",
    "mysql_cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS stock_tweets (\n",
    "        id INT PRIMARY KEY,\n",
    "        date DATE,\n",
    "        ticker VARCHAR(10),\n",
    "        tweet TEXT\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Create single table for all stock prices\n",
    "mysql_cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS stock_prices (\n",
    "        date DATE,\n",
    "        open FLOAT,\n",
    "        high FLOAT,\n",
    "        low FLOAT,\n",
    "        close FLOAT,\n",
    "        adj_close FLOAT,\n",
    "        volume BIGINT,\n",
    "        ticker VARCHAR(10)\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "# Commit changes to create tables\n",
    "mysql_conn.commit()\n",
    "print(\"MySQL tables created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4217586-e311-48bb-a0b7-1a9f66df14c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Import libraries for data manipulation\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define paths to CSV files\n",
    "tweets_file = \"stocktweet/stocktweet.csv\"  # Replace with the path to your stock tweets CSV\n",
    "stock_files_path = \"stockprice/*.csv\"  # Replace with the path to your stock prices folder\n",
    "\n",
    "# Load stock tweets data\n",
    "tweets_df = pd.read_csv(tweets_file)\n",
    "\n",
    "# Load each stock price file and add ticker column\n",
    "stock_dataframes = {}\n",
    "for file in glob.glob(stock_files_path):\n",
    "    ticker = os.path.basename(file).replace(\".csv\", \"\")\n",
    "    df = pd.read_csv(file)\n",
    "    df['ticker'] = ticker  # Add ticker column to identify the stock\n",
    "    stock_dataframes[ticker] = df\n",
    "\n",
    "print(\"Data loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77c1d6f6-9b39-461f-90d1-ef63a08b5970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Data cleaning\n",
    "# Check for missing values in tweets data and fill if necessary\n",
    "tweets_df.fillna(\"\", inplace=True)\n",
    "\n",
    "# Convert 'Date' columns to datetime format\n",
    "tweets_df['date'] = pd.to_datetime(tweets_df['date'], errors='coerce')\n",
    "for ticker, df in stock_dataframes.items():\n",
    "    df['date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df.dropna(subset=['date'], inplace=True)  # Drop rows with invalid dates\n",
    "\n",
    "print(\"Data cleaned successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c8608d8-535e-4fb7-a56e-08832727163d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "1062 (23000): Duplicate entry '100001' for key 'stock_tweets.PRIMARY'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mysql/connector/connection_cext.py:706\u001b[0m, in \u001b[0;36mCMySQLConnection.cmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    705\u001b[0m         query \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 706\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmysql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m: Duplicate entry '100001' for key 'stock_tweets.PRIMARY'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 6: Insert data into MySQL\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Insert tweets data into MySQL\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m tweets_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mmysql_cursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m        INSERT INTO stock_tweets (id, date, ticker, tweet)\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m        VALUES (\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mticker\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtweet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Insert stock prices data into MySQL\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ticker, df \u001b[38;5;129;01min\u001b[39;00m stock_dataframes\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mysql/connector/cursor_cext.py:357\u001b[0m, in \u001b[0;36mCMySQLCursor.execute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ProgrammingError(\n\u001b[1;32m    353\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot all parameters were used in the SQL statement\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m             )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcmd_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[1;32m    365\u001b[0m         msg\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mmsg, errno\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39merrno, sqlstate\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39msqlstate\n\u001b[1;32m    366\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mysql/connector/opentelemetry/context_propagation.py:97\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[0;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# pylint: disable=possibly-used-before-assignment\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OTEL_ENABLED \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cnx\u001b[38;5;241m.\u001b[39motel_context_propagation:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m current_span \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mget_current_span()\n\u001b[1;32m    100\u001b[0m tp_header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mysql/connector/connection_cext.py:714\u001b[0m, in \u001b[0;36mCMySQLConnection.cmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmysql\u001b[38;5;241m.\u001b[39mquery(\n\u001b[1;32m    707\u001b[0m         query,\n\u001b[1;32m    708\u001b[0m         raw\u001b[38;5;241m=\u001b[39mraw,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    711\u001b[0m         query_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_attrs,\n\u001b[1;32m    712\u001b[0m     )\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 714\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[1;32m    715\u001b[0m         err\u001b[38;5;241m.\u001b[39merrno, msg\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mmsg, sqlstate\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39msqlstate\n\u001b[1;32m    716\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    718\u001b[0m     addr \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unix_socket \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unix_socket \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_host\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_port\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    720\u001b[0m     )\n",
      "\u001b[0;31mIntegrityError\u001b[0m: 1062 (23000): Duplicate entry '100001' for key 'stock_tweets.PRIMARY'"
     ]
    }
   ],
   "source": [
    "# Cell 6: Insert data into MySQL\n",
    "# Insert tweets data into MySQL\n",
    "for _, row in tweets_df.iterrows():\n",
    "    mysql_cursor.execute(\"\"\"\n",
    "        INSERT INTO stock_tweets (id, date, ticker, tweet)\n",
    "        VALUES (%s, %s, %s, %s)\n",
    "    \"\"\", (\n",
    "        row['id'], row['date'], row['ticker'], row['tweet']\n",
    "    ))\n",
    "\n",
    "# Insert stock prices data into MySQL\n",
    "for ticker, df in stock_dataframes.items():\n",
    "    for _, row in df.iterrows():\n",
    "        mysql_cursor.execute(\"\"\"\n",
    "            INSERT INTO stock_prices (date, open, high, low, close, adj_close, volume, ticker)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\", (\n",
    "            row['date'], row['Open'], row['High'], row['Low'], row['Close'],\n",
    "            row['Adj Close'], row['Volume'], row['ticker']\n",
    "        ))\n",
    "\n",
    "# Commit changes\n",
    "mysql_conn.commit()\n",
    "print(\"Data inserted into MySQL successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1fed4e8f-2025-496e-8b0b-d584ee5e2e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside date time if condtion\n",
      "Processed tweets_df datetime values: 0   2020-01-01\n",
      "1   2020-01-01\n",
      "2   2020-01-01\n",
      "3   2020-01-01\n",
      "4   2020-01-01\n",
      "Name: datetime, dtype: datetime64[ns]\n",
      "          id       date ticker  \\\n",
      "0     100001 2020-01-01   AMZN   \n",
      "1     100002 2020-01-01   TSLA   \n",
      "2     100003 2020-01-01   AAPL   \n",
      "3     100004 2020-01-01   TSLA   \n",
      "4     100005 2020-01-01   TSLA   \n",
      "...      ...        ...    ...   \n",
      "9995  109996        NaT   ABNB   \n",
      "9996  109997        NaT   TSLA   \n",
      "9997  109998        NaT   BABA   \n",
      "9998  109999        NaT    CCL   \n",
      "9999  110000        NaT   TSLA   \n",
      "\n",
      "                                                  tweet   datetime  \n",
      "0          $AMZN Dow futures up by 100 points already 🥳 2020-01-01  \n",
      "1     $TSLA Daddy's drinkin' eArly tonight! Here's t... 2020-01-01  \n",
      "2     $AAPL We’ll been riding since last December fr... 2020-01-01  \n",
      "3               $TSLA happy new year, 2020, everyone🍷🎉🙏 2020-01-01  \n",
      "4     $TSLA haha just a collection of greats...\"Mars... 2020-01-01  \n",
      "...                                                 ...        ...  \n",
      "9995  $ABNB “sugar daddy puts.” Don’t mind me, I’m j...        NaT  \n",
      "9996  $TSLA \\nGood news... now bears can get help wh...        NaT  \n",
      "9997  $BABA Who else is glad they sold in 240s yeste...        NaT  \n",
      "9998       $CCL $23 calls for .79 you know what to do 🥳        NaT  \n",
      "9999  $TSLA  🔥 closed out 15k in profit!Happy New Ye...        NaT  \n",
      "\n",
      "[10000 rows x 5 columns]\n",
      "Error inserting tweets into MongoDB: NaTType does not support utcoffset\n",
      "254 records for META inserted into MongoDB.\n",
      "254 records for UNH inserted into MongoDB.\n",
      "254 records for NKE inserted into MongoDB.\n",
      "254 records for CVX inserted into MongoDB.\n",
      "254 records for AAPL inserted into MongoDB.\n",
      "254 records for NFLX inserted into MongoDB.\n",
      "254 records for ^GSPC inserted into MongoDB.\n",
      "254 records for KO inserted into MongoDB.\n",
      "254 records for GOOGL inserted into MongoDB.\n",
      "254 records for PYPL inserted into MongoDB.\n",
      "254 records for MCD inserted into MongoDB.\n",
      "15 records for ABNB inserted into MongoDB.\n",
      "254 records for MSFT inserted into MongoDB.\n",
      "254 records for BAC inserted into MongoDB.\n",
      "254 records for XOM inserted into MongoDB.\n",
      "254 records for BABA inserted into MongoDB.\n",
      "254 records for TM inserted into MongoDB.\n",
      "254 records for LOW inserted into MongoDB.\n",
      "254 records for DIS inserted into MongoDB.\n",
      "254 records for PFE inserted into MongoDB.\n",
      "254 records for GOOG inserted into MongoDB.\n",
      "254 records for FB inserted into MongoDB.\n",
      "254 records for WMT inserted into MongoDB.\n",
      "254 records for SBUX inserted into MongoDB.\n",
      "254 records for JNJ inserted into MongoDB.\n",
      "254 records for AMZN inserted into MongoDB.\n",
      "254 records for TSM inserted into MongoDB.\n",
      "254 records for AMT inserted into MongoDB.\n",
      "254 records for JPM inserted into MongoDB.\n",
      "254 records for BRK-B inserted into MongoDB.\n",
      "254 records for BKNG inserted into MongoDB.\n",
      "254 records for BA inserted into MongoDB.\n",
      "254 records for UPS inserted into MongoDB.\n",
      "254 records for MA inserted into MongoDB.\n",
      "254 records for HD inserted into MongoDB.\n",
      "254 records for CCL inserted into MongoDB.\n",
      "254 records for NVDA inserted into MongoDB.\n",
      "254 records for TSLA inserted into MongoDB.\n",
      "254 records for V inserted into MongoDB.\n",
      "254 records for BRK-A inserted into MongoDB.\n",
      "254 records for PG inserted into MongoDB.\n",
      "Data insertion completed.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Insert data into MongoDB\n",
    "\n",
    "# MongoDB collections for tweets and stock prices\n",
    "tweets_collection = mongo_db['stock_tweets']\n",
    "prices_collection = mongo_db['stock_prices']\n",
    "\n",
    "# Ensure datetime column in tweets data is correctly parsed and NaT values are handled\n",
    "if 'date' in tweets_df.columns:\n",
    "    # Convert invalid datetime entries to None\n",
    "    def convert_to_datetime(value):\n",
    "        try:\n",
    "            # Try converting to datetime\n",
    "            return pd.to_datetime(value)\n",
    "        except (ValueError, TypeError):\n",
    "            # If conversion fails, return None\n",
    "            return None\n",
    "    print('inside date time if condtion')\n",
    "    tweets_df['datetime'] = tweets_df['date'].apply(convert_to_datetime)\n",
    "    print(\"Processed tweets_df datetime values:\", tweets_df['datetime'].head())  # Debugging output\n",
    "print(tweets_df)\n",
    "# Insert tweets data into MongoDB with error handling\n",
    "try:\n",
    "    tweets_collection.insert_many(tweets_df.to_dict(orient='records'))\n",
    "    print(f\"{len(tweets_df)} tweets inserted into MongoDB.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inserting tweets into MongoDB: {e}\")\n",
    "\n",
    "# Insert stock prices data into MongoDB\n",
    "for ticker, df in stock_dataframes.items():\n",
    "    # Ensure datetime column in stock data is correctly parsed and NaT values are handled\n",
    "    if 'datetime' in df.columns:\n",
    "        # Convert invalid datetime entries to NaT, then replace NaT with None for MongoDB\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce').apply(lambda x: None if pd.isna(x) else x)\n",
    "        print(f\"Processed datetime values for {ticker}:\", df['datetime'].head())  # Debugging output\n",
    "\n",
    "    try:\n",
    "        records = df.to_dict(orient='records')\n",
    "        prices_collection.insert_many(records)\n",
    "        print(f\"{len(records)} records for {ticker} inserted into MongoDB.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting stock prices for {ticker} into MongoDB: {e}\")\n",
    "\n",
    "print(\"Data insertion completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "499d3795-36ea-4de9-ac29-8c3cdf48408a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connections closed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Close connections\n",
    "mysql_cursor.close()\n",
    "mysql_conn.close()\n",
    "mongo_client.close()\n",
    "\n",
    "print(\"Connections closed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1a083-10e2-473c-b47d-6829e85712ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
